export interface BlogPost {
  slug: string
  title: string
  excerpt: string
  category: string
  date: string
  readTime: string
  author: string
  featured?: boolean
  content: string
}

export const blogPosts: BlogPost[] = [
  {
    slug: "take-it-down-act-what-it-means-for-deepfake-victims",
    title: "The TAKE IT DOWN Act: What It Means for Deepfake Victims in 2026",
    excerpt:
      "The first major federal law targeting AI-generated intimate imagery is now in effect. Here's what victims need to know about their new rights and how platforms must respond within 48 hours.",
    category: "Legislation",
    date: "2026-02-10",
    readTime: "8 min read",
    author: "AIFakeRemoval Team",
    featured: true,
    content: `The landscape of deepfake regulation changed dramatically when President Trump signed the TAKE IT DOWN Act into law on May 19, 2025. As of May 2026, every major online platform is now legally required to comply — and this changes everything for victims of AI-generated non-consensual content.

## What Is the TAKE IT DOWN Act?

The Tools to Address Known Exploitation by Immobilizing Technological Deepfakes on Websites and Networks (TAKE IT DOWN) Act is the first substantial federal law in the United States that directly criminalizes the publication of non-consensual intimate imagery, including AI-generated deepfakes.

Passed with nearly unanimous bipartisan support, the law establishes two critical pillars:

**Criminal penalties** for anyone who knowingly publishes intimate images — real or AI-generated — without the depicted person's consent. Violations carry up to two years in prison for crimes against adults and three years for crimes involving minors.

**Platform obligations** requiring covered online platforms to remove reported content within 48 hours of receiving a verified request. Platforms must also remove identical copies and take reasonable steps to prevent the content from being re-uploaded.

## What This Means for Victims

If you've discovered AI-generated intimate content depicting you online, the TAKE IT DOWN Act gives you significantly more leverage than you had before:

### 1. Platforms Must Act Within 48 Hours

Previously, platforms could take weeks or months to respond to removal requests — if they responded at all. Now, any platform hosting user-generated content must remove reported non-consensual intimate imagery within 48 hours. This includes AI-generated deepfakes that are realistic enough that a reasonable person could mistake them for authentic.

### 2. Copies Must Also Be Removed

Platforms aren't just required to remove the specific reported content. They must also remove identical copies of the material and take reasonable steps to prevent it from being re-posted.

### 3. Criminal Prosecution Is Now Possible

For the first time at the federal level, creating and distributing deepfake intimate imagery is a criminal offense. This gives law enforcement a clear legal framework to pursue perpetrators.

### 4. The FTC Enforces Compliance

The Federal Trade Commission is tasked with enforcing platform compliance, treating violations as unfair or deceptive practices. This means platforms face real consequences for failing to act.

## Key Exceptions to Know

The law includes important carve-outs. Content shared by the depicted person themselves is not covered. The law also exempts disclosures made for lawful law enforcement investigations, legal proceedings, medical treatment, and reporting unlawful conduct.

## How to Use the TAKE IT DOWN Act

If you need to file a removal request under this law:

1. **Document everything** — take screenshots, save URLs, and note timestamps before filing your report
2. **Use the platform's official reporting process** — every covered platform must now have a clear, accessible complaint mechanism
3. **Verify your identity** — platforms may require identity verification to process requests
4. **Track the 48-hour deadline** — if the platform fails to act within 48 hours, they may be in violation of federal law
5. **Consider professional help** — specialized removal services can coordinate multi-platform takedowns and ensure compliance

## The Bigger Picture

The TAKE IT DOWN Act is a watershed moment, but it's not a complete solution. Content hosted on platforms outside US jurisdiction, encrypted messaging apps, and the dark web may fall outside its reach. This is why a comprehensive removal strategy — combining legal frameworks, platform reporting, and professional monitoring — remains essential.

At AIFakeRemoval, we've updated all our processes to leverage these new legal requirements. If you're dealing with non-consensual AI-generated content, you now have more tools than ever before. Don't wait — the sooner you act, the more effective removal efforts will be.`,
  },
  {
    slug: "how-to-report-deepfakes-platform-by-platform-guide",
    title: "How to Report and Remove Deepfakes: Instagram, TikTok, X, Reddit Guide (2026)",
    excerpt:
      "Someone posted a fake AI image of you on Instagram, TikTok, X, or Reddit? Every platform has a different reporting process. This step-by-step guide walks you through exactly what to do on each one.",
    category: "Guides",
    date: "2026-01-28",
    readTime: "10 min read",
    author: "AIFakeRemoval Team",
    content: `Discovering a deepfake of yourself online is alarming. Your first instinct might be to panic, but the most important thing you can do is act quickly and strategically. Every major platform has specific processes for reporting manipulated content — and knowing the right steps for each one can mean the difference between a quick removal and weeks of frustration.

## Before You Report: Essential Documentation

Before filing any report, take these critical steps:

- **Screenshot everything** — capture the content, the profile posting it, any comments, and the full URL
- **Save direct URLs** — copy the exact link to the content, not just the profile page
- **Note timestamps** — record when you first discovered the content and when it appears to have been posted
- **Preserve evidence** — use a web archive tool or save pages offline in case content is deleted before platforms review it
- **Do not engage** — don't comment on, share, or interact with the content

## Meta Platforms (Facebook, Instagram, Threads)

Meta has implemented dedicated reporting for deepfake intimate imagery. To report:

1. Open the content and tap the three dots (⋯) menu
2. Select **"Report"** then **"Nudity or sexual activity"**
3. For deepfakes specifically, Meta now offers **"Report deepfake intimate imagery"** as a category
4. You'll need to verify your identity through Meta's process
5. Meta is required to respond and remove verified NCII within 48 hours under the TAKE IT DOWN Act

For impersonation, use the dedicated **Impersonation Report Form** available in the Help Center.

## YouTube

YouTube handles deepfake reports through its Privacy Complaint Process:

1. Navigate to the video and click **Report** (flag icon)
2. Select **"Infringes my rights"** then **"Invades my privacy"**
3. Fill out the **Privacy Complaint Form** with your information
4. Include evidence that the content is AI-generated or manipulated
5. YouTube typically reviews within 24-48 hours

## TikTok

TikTok has expanded its AI content policies significantly:

1. Long-press on the video and tap **"Report"**
2. Select **"Fake engagement"** or **"Harassment and bullying"** depending on the nature
3. For intimate deepfakes, select **"Non-consensual intimate imagery"**
4. Provide as much context as possible in the description field
5. You can also email TikTok's legal team directly for escalated cases

## X (formerly Twitter)

X's reporting process for deepfakes:

1. Click the three dots on the post
2. Select **"Report post"** then **"Abusive or harmful"**
3. Choose **"Includes private information"** or **"Non-consensual nudity"**
4. For impersonation, use the dedicated **Impersonation Report Form**
5. X's response times vary — professional escalation may be needed for urgent cases

## Google Search De-Indexing

Even after content is removed from a platform, it may still appear in search results:

1. Use **Google's Content Removal Tool** to request de-indexing
2. For NCII specifically, use the **Personal content removal request form**
3. Google also accepts DMCA takedown requests if your likeness was used without authorization
4. De-indexing typically takes 1-4 weeks

## When Platform Reporting Isn't Enough

Standard reporting processes fail more often than you'd expect. Common reasons include:

- Automated review systems missing context
- Content being classified incorrectly
- Platforms claiming the content doesn't violate their specific policies
- Delays beyond the 48-hour requirement

When this happens, escalation pathways become critical. Professional removal services have direct contacts, knowledge of hidden reporting channels, and experience with the specific language and documentation that triggers faster action.

## What If Content Is on an Unknown Platform?

For content hosted on less well-known platforms, forums, or independent websites:

1. Perform a **WHOIS lookup** to find the domain owner
2. Contact the site's **abuse email** (usually abuse@domain.com)
3. File a **DMCA takedown notice** with the hosting provider
4. If the site is hosted in the US, reference the TAKE IT DOWN Act
5. Consider engaging professional help for multi-site coordination

Speed matters. Content that stays online longer becomes harder to fully remove as it gets cached, downloaded, and re-shared. If you're dealing with deepfake content, don't hesitate to seek professional help.`,
  },
  {
    slug: "ai-deepfake-detection-how-experts-identify-fake-content",
    title: "How to Tell If an Image Is AI-Generated: Expert Detection Methods (2026)",
    excerpt:
      "Is that image of you real or AI-generated? Deepfakes are nearly impossible to spot visually now. Learn the detection methods professionals use to prove images are fake — critical for removal requests and legal cases.",
    category: "Technology",
    date: "2026-01-15",
    readTime: "7 min read",
    author: "AIFakeRemoval Team",
    content: `As AI generation technology becomes more sophisticated, deepfakes are approaching a level of realism that makes them nearly impossible for the average person to detect. In 2026, the arms race between generation and detection has intensified — but detection technology is keeping pace. Here's how experts identify fake content today.

## Why Visual Inspection Alone Is No Longer Reliable

Just two years ago, deepfakes often had telltale signs: distorted hands, inconsistent lighting, blurred edges around hair, or unnatural eye reflections. Modern generation models — particularly those based on diffusion architectures — have largely eliminated these obvious artifacts.

Today's AI-generated images can produce photorealistic skin textures, accurate reflections, consistent lighting, and anatomically correct details. Relying on "looking closely" is no longer a viable detection strategy.

## Multi-Layer Detection Approaches

Modern deepfake detection uses multiple analytical layers simultaneously:

### 1. Pixel-Level Analysis

Advanced detection tools examine images at the pixel level, looking for statistical anomalies invisible to the human eye. AI-generated images leave subtle mathematical "fingerprints" in how pixel values are distributed — patterns that differ from photographs captured by real cameras.

### 2. Metadata Forensics

Every digital image contains metadata — information about the camera, software, creation date, and editing history. AI-generated images either lack standard camera metadata entirely or contain synthetic metadata that doesn't match the claimed source.

### 3. Frequency Domain Analysis

When images are transformed into the frequency domain (using techniques like Fourier transforms), AI-generated content reveals distinctive patterns. Real photographs have a natural frequency distribution created by optical physics, while synthetic images show artificial frequency signatures unique to the generation model used.

### 4. Semantic Consistency Checks

Detection systems analyze whether the content of an image is internally consistent. This includes checking for impossible physics (shadows going in different directions), inconsistent depth of field, or geometric impossibilities that generation models sometimes produce.

### 5. Provenance Verification

The Content Authenticity Initiative (CAI) and C2PA standards are increasingly being adopted by camera manufacturers and platforms. These systems embed cryptographic signatures at the point of capture, creating a verifiable chain of custody. Content without provenance data is increasingly treated with suspicion.

## Platform-Level Detection at Scale

Major platforms have deployed detection at massive scale:

**Sensity AI** and similar services offer multi-layer detection analyzing visual content, file structure, metadata, and audio signals simultaneously. These tools can process millions of images and flag potential deepfakes with increasing accuracy.

**DeepFake-O-Meter v2.0** — an open-source platform — integrates state-of-the-art detection methods for images, video, and audio, serving both researchers and everyday users.

## The Generalization Problem

One of the biggest challenges in deepfake detection is generalization. A detector trained to identify deepfakes from one AI model may completely miss those generated by a different model. Research presented at IEEE EuroS&P 2025 found that many leading detectors struggle significantly when encountering content from unseen generation methods.

This is why the best detection strategies use ensembles — multiple detection methods running simultaneously — rather than relying on any single approach.

## What This Means for Victims

If you suspect content depicting you is AI-generated:

1. **Don't try to determine authenticity yourself** — professional analysis is far more reliable
2. **Preserve the original file** — don't screenshot it; download the original if possible, as compression destroys forensic evidence
3. **Report it regardless** — even if you're not 100% certain it's fake, platforms are required to investigate
4. **Professional forensic analysis** can provide documentation that strengthens your removal requests and any legal proceedings

Detection technology is a critical tool in the fight against deepfakes, but it's most powerful when combined with rapid reporting, legal frameworks like the TAKE IT DOWN Act, and professional removal services that know how to leverage all available tools.`,
  },
  {
    slug: "protecting-your-digital-identity-prevention-guide",
    title: "How to Prevent AI Fakes of You: Digital Identity Protection Guide (2026)",
    excerpt:
      "How to stop someone from making fake AI images of you. Practical steps to reduce your risk, monitor your online presence, lock down your photos, and act fast if your likeness is misused.",
    category: "Prevention",
    date: "2026-01-02",
    readTime: "6 min read",
    author: "AIFakeRemoval Team",
    content: `While no prevention method is foolproof against determined bad actors, there are concrete steps you can take to reduce your risk profile and ensure you catch any misuse of your likeness early. Prevention and early detection are far more effective than trying to remove content after it has spread widely.

## Understanding Your Risk Profile

Anyone can be targeted by deepfake creation, but certain factors increase risk:

- **Public-facing professionals** — executives, politicians, attorneys, physicians
- **Content creators** — YouTubers, streamers, models, influencers
- **Public figures** — anyone with significant media presence
- **Active social media users** — more available photos mean easier deepfake creation

Understanding your risk level helps you calibrate the right level of preventive measures.

## Audit Your Digital Footprint

### Social Media Settings

Review privacy settings on every platform:

- Set photo albums to **private or friends-only**
- Disable the ability for others to **tag you in photos** without approval
- Review and remove **old photos** that you no longer want public
- Turn off **facial recognition** features where available
- Consider limiting who can **download your photos**

### Image Search Yourself

Regularly search for your images across the web:

- Use **Google Images** reverse search with your photos
- Try **TinEye** for broader image matching
- Search your name combined with terms like "photo," "image," or "video"
- Set up **Google Alerts** for your name and common variations

### Professional Headshots and Public Photos

If your profession requires public photos:

- Limit the **number of high-resolution images** available publicly
- Use **consistent, professional headshots** rather than casual photos
- Consider adding invisible **watermarks** to images you publish
- Use platforms that support **C2PA content credentials** when available

## Digital Monitoring Strategies

### Automated Monitoring

Set up automated systems to catch misuse early:

1. **Google Alerts** — create alerts for your full name, username variants, and business name
2. **Social media monitoring** — use tools to scan for new accounts using your name or photo
3. **Reverse image search monitoring** — periodic automated searches for your photos
4. **Dark web monitoring** — for high-risk individuals, monitoring services can scan less accessible areas of the internet

### Manual Checks

Schedule regular manual checks:

- Monthly review of Google Image search results for your name
- Quarterly audit of social media platforms for impersonation accounts
- Annual review of all privacy settings across platforms

## Technical Prevention Measures

### Content Credentials

The **C2PA standard** (Coalition for Content Provenance and Authenticity) allows cameras and software to embed cryptographic proof of when and how an image was created. As adoption grows, content without credentials will face increasing scrutiny.

### Watermarking Technology

Invisible digital watermarks can be embedded in your photos before sharing. While not foolproof, they create an additional evidence trail that can:

- Prove original ownership in disputes
- Help track where images have been shared
- Strengthen takedown requests

### Social Media Hardening

Beyond privacy settings, consider:

- Using **two-factor authentication** on all accounts
- Removing **location data** from photos before posting
- Being selective about **friend/follower requests** from unknown people
- Avoiding **face filter apps** from unknown developers (they may harvest facial data)

## If Prevention Fails: Early Response

Despite best efforts, prevention may not be enough. If you discover misuse:

1. **Don't panic, but act fast** — the first 24-48 hours are critical
2. **Document everything** before the content might be removed or altered
3. **Don't engage** with the perpetrator or the content publicly
4. **File reports immediately** on every platform where the content appears
5. **Contact professional help** — specialized removal services can coordinate multi-platform action far more efficiently than individual reporting

## Building Long-Term Resilience

Digital identity protection isn't a one-time action — it's an ongoing practice. Build habits:

- Review privacy settings whenever platforms update their policies
- Be mindful of what you share publicly, especially high-resolution facial images
- Stay informed about new threats and new protection tools
- Have a response plan ready before you need it

The goal isn't to disappear from the internet — it's to maintain control over how your likeness is used and to be prepared to act decisively if that control is threatened.`,
  },
  {
    slug: "deepfake-crisis-management-for-businesses",
    title: "Someone Made a Deepfake of Your CEO: Business Crisis Response Playbook",
    excerpt:
      "A fake AI image of your executive is spreading online. What do you do in the first 2 hours? The first 24? Here's the enterprise playbook for deepfake incident response — from detection to removal to recovery.",
    category: "Business",
    date: "2025-12-18",
    readTime: "9 min read",
    author: "AIFakeRemoval Team",
    content: `Deepfake threats to businesses are accelerating. From fabricated CEO statements that move stock prices to fraudulent video calls that authorize wire transfers, organizations face a growing array of AI-generated threats. The companies that weather these crises successfully are the ones with a playbook ready before the incident occurs.

## The Business Threat Landscape

Deepfakes target businesses in several ways:

### Executive Impersonation
AI-generated video or audio of C-suite executives has been used to authorize fraudulent transactions, issue fake statements, and manipulate stakeholders. In one notable case, a deepfake CFO on a video call convinced a finance employee to transfer $25 million.

### Brand Manipulation
Fabricated product announcements, fake customer testimonials, and synthetic brand communications can damage consumer trust and market position.

### Employee Targeting
Employees may be targeted with deepfake harassment, impersonation, or disinformation campaigns that create internal disruption.

### Competitive Sabotage
Competitors or bad actors may use deepfakes to create false impressions of corporate misconduct, environmental violations, or legal problems.

## The Incident Response Framework

### Phase 1: Detection and Verification (0-2 Hours)

**Immediate actions when a potential deepfake is identified:**

1. **Alert the incident response team** — this should include communications, legal, IT security, and executive leadership
2. **Verify authenticity** — engage forensic analysis to confirm whether the content is AI-generated
3. **Assess the scope** — determine where the content has appeared and how widely it has spread
4. **Preserve evidence** — capture and document all instances of the content with timestamps and URLs
5. **Do not publicly acknowledge** the deepfake until verification is complete and a response strategy is in place

### Phase 2: Containment (2-24 Hours)

**Once the deepfake is confirmed:**

1. **File platform removal requests** — submit reports on every platform where the content appears, citing the TAKE IT DOWN Act where applicable
2. **Issue internal communications** — brief employees about the incident and provide talking points
3. **Engage search engine de-indexing** — request removal from Google, Bing, and other search engines
4. **Contact law enforcement** — if the deepfake involves fraud, market manipulation, or threats
5. **Engage professional removal services** — coordinate multi-platform takedowns through experienced specialists

### Phase 3: Public Response (24-72 Hours)

**Crafting the external narrative:**

1. **Prepare a clear, factual statement** — acknowledge the deepfake without amplifying its message
2. **Provide verification** — offer proof of authenticity for legitimate communications (e.g., official channels, signed statements)
3. **Brief key stakeholders** — investors, board members, major clients, and partners
4. **Monitor media coverage** — track how the story is being covered and correct misinformation promptly
5. **Document the timeline** — maintain a detailed record for potential legal proceedings

### Phase 4: Recovery and Hardening (Ongoing)

**After the immediate crisis:**

1. **Conduct a post-incident review** — what worked, what didn't, and what needs improvement
2. **Update authentication protocols** — implement verification steps for high-stakes communications
3. **Establish content provenance** — adopt C2PA standards for official communications
4. **Train employees** — ensure staff can recognize potential deepfakes and know the reporting process
5. **Set up ongoing monitoring** — automated scanning for new instances or variations

## Building Organizational Resilience

### Authentication Infrastructure

Implement systems that make it harder for deepfakes to succeed:

- **Code words or verification phrases** for high-value transactions
- **Multi-channel confirmation** for sensitive directives (e.g., confirming a video call request via a separate text message)
- **Digital signatures** on official communications
- **Regular rotation** of authentication methods

### Employee Training

Make deepfake awareness part of your security culture:

- Annual training on recognizing AI-generated content
- Simulated deepfake exercises (similar to phishing simulations)
- Clear escalation paths for reporting suspicious content
- Emphasis that verification requests are never inappropriate, regardless of who appears to be asking

### Vendor and Partner Coordination

Your response is only as strong as your weakest link:

- Ensure key partners have compatible incident response processes
- Establish verified communication channels for crisis scenarios
- Include deepfake provisions in vendor security agreements
- Share threat intelligence with industry peers

## The Cost of Inaction

Organizations without a deepfake response plan face:

- **Reputational damage** that compounds with every hour of delayed response
- **Financial losses** from fraud, market manipulation, or customer attrition
- **Legal liability** for failing to protect stakeholder interests
- **Employee morale** impacts from feeling unprotected

The investment in preparation is minimal compared to the potential cost of an unmanaged deepfake crisis. Start building your playbook today.`,
  },
  {
    slug: "the-psychology-of-deepfake-victimization",
    title: "I Found a Deepfake of Myself: The Psychological Impact and How to Cope",
    excerpt:
      "Discovering a fake AI image of yourself causes real psychological harm — shame, anxiety, hypervigilance, trust erosion. You're not overreacting. Here's what victims experience and how to recover.",
    category: "Awareness",
    date: "2025-12-05",
    readTime: "7 min read",
    author: "AIFakeRemoval Team",
    content: `The psychological impact of discovering a deepfake of yourself is often compared to that of identity theft, sexual assault, or cyberstalking. Yet the unique nature of deepfake victimization — seeing a synthetic version of yourself doing things you never did — creates a distinct form of trauma that is only beginning to be understood.

## The Unique Harm of Deepfakes

Unlike other forms of online harassment, deepfake victimization involves:

### Loss of Bodily Autonomy
Victims experience their likeness being used in ways they never consented to. This creates a profound sense of violation — your own face and body have been weaponized against you, and you had no control over it.

### Persistent Uncertainty
Once a deepfake exists, victims often experience ongoing anxiety about who has seen it, where it might reappear, and whether it will surface at a critical moment — a job interview, a relationship, a professional milestone.

### The Authenticity Trap
Even when content is proven to be AI-generated, the doubt it creates can be devastating. Victims report that friends, family, and colleagues sometimes harbor lingering doubts, regardless of evidence proving the content is fake.

### Compounded by Virality
The speed at which content spreads online means that by the time a victim discovers a deepfake, hundreds or thousands of people may have already seen it. This amplifies the sense of helplessness and loss of control.

## Common Psychological Responses

Research and clinical experience reveal several patterns in deepfake victimization:

### Acute Stress Response
In the immediate aftermath of discovery, victims commonly experience shock, disbelief, nausea, panic attacks, and difficulty concentrating. This is a normal response to an abnormal situation.

### Shame and Self-Blame
Many victims experience shame — even though they did nothing wrong. This is particularly pronounced with intimate deepfakes, where victims may internalize blame or feel reluctant to seek help.

### Hypervigilance
Victims often develop heightened anxiety about their online presence, compulsively checking platforms for new content, monitoring search results, and becoming suspicious of new social media interactions.

### Social Withdrawal
Fear of judgment leads many victims to withdraw from social situations, reduce their online presence, or avoid professional opportunities that increase visibility.

### Trust Erosion
Being targeted by a deepfake — especially by someone known to the victim — can fundamentally damage the ability to trust others, both online and offline.

## The Path to Recovery

### 1. Acknowledge the Impact

Deepfake victimization is a legitimate form of abuse. The emotional response is valid, proportionate, and expected. Minimizing the impact ("it's just a fake image") delays recovery.

### 2. Take Action

Passivity amplifies the sense of helplessness. Taking concrete steps toward removal — reporting content, engaging professionals, documenting evidence — restores a sense of agency and control.

Research consistently shows that victims who take proactive removal steps experience better psychological outcomes than those who try to "wait it out."

### 3. Build a Support System

- **Trusted individuals** — share what happened with people you trust. Isolation compounds the harm
- **Professional support** — therapists experienced in cyber-harassment and image-based abuse understand the specific dynamics
- **Peer communities** — organizations like CCRI (Cyber Civil Rights Initiative) connect victims with others who understand the experience
- **Legal counsel** — understanding your legal options reduces uncertainty and empowers action

### 4. Reclaim Your Narrative

Many victims find empowerment in:

- Speaking about their experience (when they're ready) to reduce stigma
- Advocating for stronger protections
- Helping others who face similar situations
- Rebuilding their online presence on their own terms

### 5. Long-Term Monitoring

Recovery isn't just about removing the immediate content. Ongoing monitoring provides peace of mind:

- Automated alerts for new content
- Regular check-ins on search results
- Professional monitoring services for comprehensive coverage

## A Note for Those Supporting Victims

If someone you know has been targeted:

- **Believe them** — don't question or minimize their experience
- **Don't search for the content** — this only increases its spread
- **Offer practical help** — assist with documentation, research, or contacting professionals
- **Be patient** — recovery from this kind of violation takes time
- **Respect their choices** — they decide who knows, when to report, and how to proceed

## The Importance of Professional Help

Dealing with deepfake content alone compounds the psychological harm. Professional removal services don't just handle the technical aspects — they shield victims from the re-traumatization of repeatedly viewing and describing the content, navigating bureaucratic reporting processes, and managing the anxiety of uncertain timelines.

You don't have to face this alone. Help is available, and it works.`,
  },
]

export function getBlogPost(slug: string): BlogPost | undefined {
  return blogPosts.find((post) => post.slug === slug)
}

export function getFeaturedPosts(): BlogPost[] {
  return blogPosts.filter((post) => post.featured)
}

export function getRecentPosts(count: number = 3): BlogPost[] {
  return [...blogPosts]
    .sort((a, b) => new Date(b.date).getTime() - new Date(a.date).getTime())
    .slice(0, count)
}

export function formatDate(dateString: string): string {
  return new Date(dateString).toLocaleDateString("en-US", {
    year: "numeric",
    month: "long",
    day: "numeric",
  })
}
